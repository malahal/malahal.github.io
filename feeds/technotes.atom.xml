<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Malahal blog - technotes</title><link href="http://malahal.github.io/" rel="alternate"></link><link href="http://malahal.github.io/feeds/technotes.atom.xml" rel="self"></link><id>http://malahal.github.io/</id><updated>2013-01-19T00:00:00+05:30</updated><entry><title>technotes</title><link href="http://malahal.github.io/technotes.html" rel="alternate"></link><published>2013-01-19T00:00:00+05:30</published><updated>2013-01-19T00:00:00+05:30</updated><author><name>Malahal Naineni</name></author><id>tag:malahal.github.io,2013-01-19:/technotes.html</id><summary type="html">&lt;p class="first last"&gt;Technical cheat sheet for my own consumption!&lt;/p&gt;
</summary><content type="html">&lt;p&gt;All in a single page for now!&lt;/p&gt;
&lt;div class="section" id="netcat"&gt;
&lt;h2&gt;netcat&lt;/h2&gt;
&lt;div class="section" id="test-your-network-speed-using-netcat"&gt;
&lt;h3&gt;Test your network speed using netcat&lt;/h3&gt;
&lt;p&gt;On one node, start netcat in listening mode:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
nc -v -l -p 2222 &amp;gt; /dev/null # -p may not be needed in some versions
&lt;/pre&gt;
&lt;p&gt;On the other node, send the data as below:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pv /dev/zero | nc -v &amp;lt;ip-address-of-node-one&amp;gt; 2222
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="ssh"&gt;
&lt;h2&gt;ssh&lt;/h2&gt;
&lt;p&gt;ssh-copy-id with a non default port&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssh-copy-id &amp;quot;user&amp;#64;host -p 1234&amp;quot;
&lt;/pre&gt;
&lt;p&gt;ssh execute arbitrary script on a remote machine!&lt;/p&gt;
&lt;pre class="literal-block"&gt;
ssh user&amp;#64;remotehost &amp;quot;echo `base64 script.sh` | base64 -d | sudo
bash&amp;quot;
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="rsync"&gt;
&lt;h2&gt;Rsync&lt;/h2&gt;
&lt;div class="section" id="pulling-only-few-files"&gt;
&lt;h3&gt;pulling only few files&lt;/h3&gt;
&lt;p&gt;Rsync is a nice file synchroniser. If you want to pull only few files,
the syntax is a bit confusing though. The following would pull the
matched files and all directory entries.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rsync -av --include '*.jpg' --include '*/' --exclude '*' host:src dst
&lt;/pre&gt;
&lt;p&gt;It will not pull any jpeg files under subdirectories if you don't
include the second --include! Of course, you can use _find_ to prune the
empty directories as below.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
find . -type d -empty -delete
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="copying-a-very-large-file-over-a-slow-link"&gt;
&lt;h3&gt;Copying a very large file over a slow link&lt;/h3&gt;
&lt;p&gt;It is probably easier to use __lftp__ to do this but not all sites provide
ftp service. __ssh__ is ubiquitous, so you can use rsync as below:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rsync -a --partial --progress host:src dst
&lt;/pre&gt;
&lt;p&gt;If you need to restart:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rsync -a --partial --append --progress host:src dst
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="rsync-with-non-standard-ssh-port"&gt;
&lt;h3&gt;Rsync with non-standard ssh port&lt;/h3&gt;
&lt;p&gt;Example with port 1602:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
rsync -e 'ssh -p 1602' user&amp;#64;dest:/path/to/files /local/path
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="running-rsync-with-an-intermediate-hop"&gt;
&lt;h3&gt;Running rsync with an intermediate hop!&lt;/h3&gt;
&lt;p&gt;See the link &lt;a class="reference external" href="http://rsync.samba.org/firewall.html"&gt;http://rsync.samba.org/firewall.html&lt;/a&gt; for now.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="tcpdump"&gt;
&lt;h2&gt;tcpdump&lt;/h2&gt;
&lt;p&gt;Some examples to capture network packets:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
tcpdump -i any -s0 -C 500 -W 20 -w /tmp/pcap.out
tcpdump -i any -s250 -C 500 -W 20 -w /tmp/pcap.out port nfs
tcpdump -i any -s250 -C 500 -W 20 -w /tmp/pcap.out port nfs host 192.168.1.122
&lt;/pre&gt;
&lt;p&gt;On some older systems, -C or -W option causes tcpdump to run as tcpdump
user. Use &amp;quot;-Z root&amp;quot; to run it as root.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="tshark-wireshark-time-zone"&gt;
&lt;h2&gt;tshark/wireshark time zone&lt;/h2&gt;
&lt;p&gt;Wireshark/tshark use local system time zone. If the capture is done
in a different time zone, set TZ environment to display time in the
captured time zone. Use tzselect for the exact string for the TZ
environment variable. For example:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
TZ='America/Phoenix' capinfos -ae tcpdump.pcap
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="gnu-parallel-and-xargs"&gt;
&lt;h2&gt;GNU Parallel and xargs&lt;/h2&gt;
&lt;p&gt;[GNU parallel][xxx] is written with parallelization in mind. It uses the
number of CPU threads in the system by default. It is not already
installed on most distros, but xargs is, and has this feature as well.
Without -n option, xargs may try to pass all input arguments to a single
command. So always provide -n option with -P if you want to run multiple
commands in parallel.&lt;/p&gt;
&lt;pre class="literal-block"&gt;
find . -type f | xargs -P8 -n1 grep my-search-expr
find . -type f | xargs -I{} -P8 -n1 dd if={} of=/dev/null
seq 10 | xargs -I{} -P10 -n1 dd if=/tmp/samefile of=/dev/null
echo 'your list of commands' | xargs -d\n -I{} -P8 -n1 sh -c '{}'
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="python"&gt;
&lt;h2&gt;Python&lt;/h2&gt;
&lt;p&gt;Time in python:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
time.ctime()
datetime.datetime.now()
strptime and strftime.

tzpdx = dateutil.tz.tzfile(&amp;quot;/usr/share/zoneinfo/America/Los_Angeles&amp;quot;)
time = datetime.datetime.now(tzpdx).strftime(&amp;quot;%Y-%m-%d %I:%M%p&amp;quot;)
&lt;/pre&gt;
&lt;/div&gt;
&lt;div class="section" id="pelican-blog-update"&gt;
&lt;h2&gt;Pelican blog update&lt;/h2&gt;
&lt;p&gt;Edit files in content directory and run &amp;quot;pelican content&amp;quot; which will
produce static files in output directory. Copy the output to google app
engine.:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cd ~/pelican; edit content/&amp;lt;files&amp;gt;
pelican content -s pelicanconf.py
cd ~/google/google_appengine
rsync -a output to static
./appcfg.py update blog-pelican/ # google app engine
&lt;/pre&gt;
&lt;/div&gt;
</content><category term="rsync"></category><category term="netcat"></category><category term="tcpdump"></category></entry></feed>